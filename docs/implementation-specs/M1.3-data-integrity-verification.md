# M1.3: Data Integrity Verification

**Status**: Draft
**Version**: 1.0
**Date**: 2025-11-18
**Dependencies**: M1.1 (Export Verification Framework)

---

## 1. Overview

### 1.1 Purpose

This specification defines a **post-load data integrity verification system** that proves the target database contains exactly the same data as the source database after executing the full-export pipeline.

**Business Goal**: Replace DMM (vendor tool) by providing end-to-end certainty that the exported dataset is byte-identical to the source, enabling deterministic, observable, and trustworthy data migrations.

**Key Capabilities**:
- Compare source (physical names) vs target (logical names) data using cryptographic hashes
- Verify row counts match across all tables
- Detect NULL preservation issues through column-level NULL count comparison
- Flag data type conversions for operator scrutiny
- Generate comprehensive verification reports with pass/fail criteria

### 1.2 Scope

**In Scope**:
- Post-load verification (after LoadHarness executes INSERT scripts)
- Full-export pipeline (NO data transformations, only name aliasing)
- Tables with up to ~100k rows (user-confirmed maximum)
- All columns in dbo schema scope
- Physical→Logical name mapping via `model.json` + naming overrides
- Cryptographic hash comparison using HASHBYTES (SHA2_256)
- Column-level NULL count verification
- Data type conversion detection and warnings

**Out of Scope** (Deferred to M2.2):
- UAT-users transformation verification (user FK remapping)
- Pre-load verification (artifact checksums covered by M1.1)
- Cross-schema verification (everything in dbo scope)
- Large table optimization (>100k rows)

### 1.3 Architectural Considerations

**Timing**: Verification runs AFTER LoadHarness completes script execution.

**Why Post-Load?**
1. **Source of Truth**: Target database is the final artifact that matters
2. **Transformation Visibility**: All name aliasing has been applied
3. **Performance Independence**: Verification doesn't block pipeline execution
4. **Fail-Safe**: Can re-run verification without re-executing expensive ETL

**Integration Points**:
- Reads `model.json` for physical→logical name mapping
- Reads `FullExportRunManifest` for metadata (entity list, timestamps)
- Uses `NamingOverrideOptions` to apply same name resolution logic as emission
- Extends `LoadHarnessReport` with data integrity metrics
- Requires source and target database connection strings

---

## 2. Success Criteria

### 2.1 Functional Requirements

1. **F1: Name Mapping Resolution**
   - GIVEN: `model.json` with physical/logical names + naming override configuration
   - WHEN: Verification builds query mappings
   - THEN: Source queries use physical names, target queries use logical names with overrides applied

2. **F2: Row Count Verification**
   - GIVEN: Source table `[dbo].[OSUSR_R2K_Order]` with N rows
   - WHEN: Verification queries source and target
   - THEN: Target table `[dbo].[Order]` must have exactly N rows

3. **F3: Hash Comparison**
   - GIVEN: Source table with data D
   - WHEN: HASHBYTES(SHA2_256) computed on both source and target (same column order)
   - THEN: Hashes must match byte-for-byte (for non-transformed columns)

4. **F4: NULL Preservation**
   - GIVEN: Source column `[EMAIL]` with M NULL values
   - WHEN: Verification compares NULL counts
   - THEN: Target column `[Email]` must have exactly M NULL values

5. **F5: Data Type Conversion Detection**
   - GIVEN: Source column type `VARCHAR(100)`, target schema expects `NVARCHAR(100)`
   - WHEN: Verification compares metadata
   - THEN: Report includes warning about type conversion (not error)

6. **F6: Comprehensive Reporting**
   - GIVEN: Verification completes for all entities
   - WHEN: Report generated
   - THEN: Report includes: pass/fail per table, row counts, hash matches, NULL counts, warnings

### 2.2 Non-Functional Requirements

1. **Performance**: Verification of ~100 tables (~100k rows each) completes within 10 minutes
2. **Reliability**: Uses SHA2_256 hashing (collision probability ~2^-128)
3. **Observability**: Detailed logging of each verification step (source query, target query, comparison)
4. **Fail-Fast**: Stop verification on connection errors, but continue on table mismatches
5. **Idempotency**: Can re-run verification multiple times with same results

---

## 3. Data Models

### 3.1 DataIntegrityVerificationContext

**Purpose**: Encapsulates all inputs required for post-load verification.

```csharp
public sealed record DataIntegrityVerificationContext(
    OsmModel Model,                           // Parsed from model.json
    FullExportRunManifest Manifest,           // Pipeline metadata
    NamingOverrideOptions NamingOverrides,    // User configuration
    string SourceConnectionString,            // QA/source database
    string TargetConnectionString,            // UAT/target database
    DateTimeOffset VerificationStartedAtUtc,
    ImmutableArray<string> EntitiesToVerify,  // Subset or all entities
    DataIntegrityVerificationOptions Options  // Verification settings
);

public sealed record DataIntegrityVerificationOptions(
    HashAlgorithm HashAlgorithm = HashAlgorithm.SHA2_256,  // Default: SHA2_256
    bool VerifyNullCounts = true,                          // Default: enabled
    bool FailFastOnMismatch = false,                       // Default: collect all mismatches
    int CommandTimeoutSeconds = 300,                       // Default: 5 minutes per table
    bool IncludeDataTypeWarnings = true                    // Default: flag conversions
);

public enum HashAlgorithm
{
    SHA2_256,   // Recommended for production
    SHA2_512    // Higher security, slower
}
```

**Factory Method**:
```csharp
public static async Task<Result<DataIntegrityVerificationContext>> CreateAsync(
    string modelJsonPath,
    string manifestPath,
    NamingOverrideOptions namingOverrides,
    string sourceConnectionString,
    string targetConnectionString,
    DataIntegrityVerificationOptions? options = null,
    CancellationToken cancellationToken = default)
{
    // 1. Load and deserialize model.json
    var modelResult = await LoadOsmModelAsync(modelJsonPath, cancellationToken);
    if (modelResult.IsFailure) return modelResult.Errors;

    // 2. Load manifest
    var manifestResult = await LoadManifestAsync(manifestPath, cancellationToken);
    if (manifestResult.IsFailure) return manifestResult.Errors;

    // 3. Determine entities to verify (from model, filtered by manifest if needed)
    var entitiesToVerify = modelResult.Value.Modules
        .SelectMany(m => m.Entities)
        .Where(e => e.IsActive && !e.IsExternal)  // Skip inactive/external
        .Select(e => $"{e.Module.Value}::{e.LogicalName.Value}")
        .ToImmutableArray();

    return new DataIntegrityVerificationContext(
        modelResult.Value,
        manifestResult.Value,
        namingOverrides,
        sourceConnectionString,
        targetConnectionString,
        TimeProvider.System.GetUtcNow(),
        entitiesToVerify,
        options ?? DataIntegrityVerificationOptions.Default
    );
}
```

---

### 3.2 TableVerificationResult

**Purpose**: Captures verification outcome for a single table.

```csharp
public sealed record TableVerificationResult(
    string ModuleName,
    string LogicalEntityName,
    string PhysicalSourceTable,
    string TargetTable,
    TableVerificationStatus Status,
    long SourceRowCount,
    long TargetRowCount,
    byte[]? SourceHash,
    byte[]? TargetHash,
    ImmutableArray<ColumnNullCountComparison> NullCountComparisons,
    ImmutableArray<DataTypeConversionWarning> TypeWarnings,
    TimeSpan Duration,
    string? ErrorMessage
);

public enum TableVerificationStatus
{
    Matched,              // All checks passed
    RowCountMismatch,     // Row counts differ
    HashMismatch,         // Hashes differ (data not identical)
    NullCountMismatch,    // NULL counts differ for one or more columns
    SourceTableMissing,   // Source table doesn't exist
    TargetTableMissing,   // Target table doesn't exist
    QueryError            // SQL execution failed
}

public sealed record ColumnNullCountComparison(
    string LogicalColumnName,
    string PhysicalColumnName,
    long SourceNotNullCount,
    long TargetNotNullCount,
    bool Matches
);

public sealed record DataTypeConversionWarning(
    string ColumnName,
    string SourceSqlType,
    string TargetSqlType,
    string Message  // e.g., "VARCHAR(100) → NVARCHAR(100): potential encoding change"
);
```

---

### 3.3 DataIntegrityVerificationReport

**Purpose**: Aggregates all table verification results with summary statistics.

```csharp
public sealed record DataIntegrityVerificationReport(
    DateTimeOffset StartedAtUtc,
    DateTimeOffset CompletedAtUtc,
    TimeSpan TotalDuration,
    int TotalTablesVerified,
    int TablesMatched,
    int TablesWithMismatches,
    int TablesWithErrors,
    ImmutableArray<TableVerificationResult> TableResults,
    ImmutableArray<string> GlobalWarnings,
    DataIntegrityVerificationStatus OverallStatus
)
{
    public static DataIntegrityVerificationReport Empty() => new(
        DateTimeOffset.UtcNow,
        DateTimeOffset.UtcNow,
        TimeSpan.Zero,
        TotalTablesVerified: 0,
        TablesMatched: 0,
        TablesWithMismatches: 0,
        TablesWithErrors: 0,
        ImmutableArray<TableVerificationResult>.Empty,
        ImmutableArray<string>.Empty,
        DataIntegrityVerificationStatus.Success
    );

    public bool IsSuccess => OverallStatus == DataIntegrityVerificationStatus.Success;
}

public enum DataIntegrityVerificationStatus
{
    Success,               // All tables matched
    PartialSuccess,        // Some tables matched, some mismatches
    Failure,               // Critical errors (e.g., connection failures)
    NotRun                 // Verification was skipped
}
```

---

## 4. Core Components

### 4.1 TableNameResolver

**Purpose**: Resolve physical→logical table/column names using model.json + naming overrides.

**Interface**:
```csharp
public interface ITableNameResolver
{
    /// <summary>
    /// Resolves the effective target table name for a given entity.
    /// </summary>
    /// <param name="entity">Entity from model.json</param>
    /// <returns>Target table name (logical or override)</returns>
    string ResolveTargetTableName(EntityModel entity);

    /// <summary>
    /// Builds a mapping of physical→logical column names for an entity.
    /// </summary>
    /// <param name="entity">Entity from model.json</param>
    /// <returns>Ordered list of (PhysicalName, LogicalName) pairs</returns>
    ImmutableArray<(string PhysicalColumnName, string LogicalColumnName)> ResolveColumnMappings(EntityModel entity);

    /// <summary>
    /// Determines the primary key column name (for ORDER BY in hash queries).
    /// </summary>
    /// <param name="entity">Entity from model.json</param>
    /// <returns>Primary key column name (physical for source, logical for target)</returns>
    (string SourcePkColumn, string TargetPkColumn) ResolvePrimaryKeyColumn(EntityModel entity);
}
```

**Implementation**:
```csharp
public sealed class TableNameResolver : ITableNameResolver
{
    private readonly NamingOverrideOptions _namingOverrides;

    public TableNameResolver(NamingOverrideOptions namingOverrides)
    {
        _namingOverrides = namingOverrides ?? throw new ArgumentNullException(nameof(namingOverrides));
    }

    public string ResolveTargetTableName(EntityModel entity)
    {
        // Use same logic as emission (NamingOverrideOptions.GetEffectiveTableName)
        return _namingOverrides.GetEffectiveTableName(
            entity.Schema.Value,
            entity.PhysicalName.Value,
            entity.LogicalName.Value,
            entity.Module.Value
        );
    }

    public ImmutableArray<(string PhysicalColumnName, string LogicalColumnName)> ResolveColumnMappings(EntityModel entity)
    {
        // Preserve order from model.json attributes array
        var builder = ImmutableArray.CreateBuilder<(string, string)>(entity.Attributes.Length);

        foreach (var attr in entity.Attributes)
        {
            if (attr.IsActive && !attr.IsDeletedFromDatabase)
            {
                builder.Add((attr.ColumnName.Value, attr.LogicalName.Value));
            }
        }

        return builder.ToImmutable();
    }

    public (string SourcePkColumn, string TargetPkColumn) ResolvePrimaryKeyColumn(EntityModel entity)
    {
        // Find primary key attribute (typically "Id")
        var pkAttr = entity.Attributes.FirstOrDefault(a => a.IsPrimaryKey);

        if (pkAttr is null)
        {
            throw new InvalidOperationException($"Entity {entity.LogicalName.Value} has no primary key.");
        }

        return (pkAttr.ColumnName.Value, pkAttr.LogicalName.Value);
    }
}
```

---

### 4.2 DataIntegrityQueryBuilder

**Purpose**: Construct SQL queries for source and target databases with identical structure.

**Interface**:
```csharp
public interface IDataIntegrityQueryBuilder
{
    /// <summary>
    /// Builds a verification query for the source database (physical names).
    /// </summary>
    string BuildSourceVerificationQuery(
        EntityModel entity,
        ImmutableArray<(string PhysicalColumnName, string LogicalColumnName)> columnMappings,
        string primaryKeyColumn,
        HashAlgorithm hashAlgorithm);

    /// <summary>
    /// Builds a verification query for the target database (logical names).
    /// </summary>
    string BuildTargetVerificationQuery(
        EntityModel entity,
        string targetTableName,
        ImmutableArray<(string PhysicalColumnName, string LogicalColumnName)> columnMappings,
        string primaryKeyColumn,
        HashAlgorithm hashAlgorithm);
}
```

**Implementation**:
```csharp
public sealed class DataIntegrityQueryBuilder : IDataIntegrityQueryBuilder
{
    public string BuildSourceVerificationQuery(
        EntityModel entity,
        ImmutableArray<(string PhysicalColumnName, string LogicalColumnName)> columnMappings,
        string primaryKeyColumn,
        HashAlgorithm hashAlgorithm)
    {
        var schema = entity.Schema.Value;
        var table = entity.PhysicalName.Value;
        var columnList = string.Join(", ", columnMappings.Select(c => $"[{c.PhysicalColumnName}]"));
        var nullCountClauses = string.Join(",\n    ", columnMappings.Select(c =>
            $"COUNT([{c.PhysicalColumnName}]) AS [{c.PhysicalColumnName}_NotNullCount]"));

        var hashAlgorithmName = hashAlgorithm switch
        {
            HashAlgorithm.SHA2_256 => "SHA2_256",
            HashAlgorithm.SHA2_512 => "SHA2_512",
            _ => throw new ArgumentOutOfRangeException(nameof(hashAlgorithm))
        };

        return $@"
SELECT
    COUNT(*) AS RowCount,
    {nullCountClauses},
    HASHBYTES('{hashAlgorithmName}',
        (SELECT {columnList}
         FROM [{schema}].[{table}]
         ORDER BY [{primaryKeyColumn}]
         FOR XML RAW, BINARY BASE64)
    ) AS TableHash
FROM [{schema}].[{table}];
";
    }

    public string BuildTargetVerificationQuery(
        EntityModel entity,
        string targetTableName,
        ImmutableArray<(string PhysicalColumnName, string LogicalColumnName)> columnMappings,
        string primaryKeyColumn,
        HashAlgorithm hashAlgorithm)
    {
        var schema = entity.Schema.Value;
        var columnList = string.Join(", ", columnMappings.Select(c => $"[{c.LogicalColumnName}]"));
        var nullCountClauses = string.Join(",\n    ", columnMappings.Select(c =>
            $"COUNT([{c.LogicalColumnName}]) AS [{c.LogicalColumnName}_NotNullCount]"));

        var hashAlgorithmName = hashAlgorithm switch
        {
            HashAlgorithm.SHA2_256 => "SHA2_256",
            HashAlgorithm.SHA2_512 => "SHA2_512",
            _ => throw new ArgumentOutOfRangeException(nameof(hashAlgorithm))
        };

        return $@"
SELECT
    COUNT(*) AS RowCount,
    {nullCountClauses},
    HASHBYTES('{hashAlgorithmName}',
        (SELECT {columnList}
         FROM [{schema}].[{targetTableName}]
         ORDER BY [{primaryKeyColumn}]
         FOR XML RAW, BINARY BASE64)
    ) AS TableHash
FROM [{schema}].[{targetTableName}];
";
    }
}
```

**Key Design Notes**:
- **Column Ordering**: Preserved from `model.json` attribute array order
- **Deterministic Row Ordering**: `ORDER BY [PrimaryKey]` ensures same hash for same data
- **NULL Handling**: Separate `COUNT(column)` for each column (NULLs excluded from count)
- **Hash Algorithm**: Configurable (SHA2_256 default, SHA2_512 for higher security)
- **FOR XML RAW, BINARY BASE64**: Serializes entire table to binary for hashing

---

### 4.3 TableVerificationExecutor

**Purpose**: Execute source and target queries, compare results, produce `TableVerificationResult`.

**Interface**:
```csharp
public interface ITableVerificationExecutor
{
    Task<TableVerificationResult> VerifyTableAsync(
        EntityModel entity,
        string sourceConnectionString,
        string targetConnectionString,
        DataIntegrityVerificationOptions options,
        CancellationToken cancellationToken = default);
}
```

**Implementation**:
```csharp
public sealed class TableVerificationExecutor : ITableVerificationExecutor
{
    private readonly ITableNameResolver _nameResolver;
    private readonly IDataIntegrityQueryBuilder _queryBuilder;
    private readonly ILogger<TableVerificationExecutor> _logger;
    private readonly TimeProvider _timeProvider;

    public TableVerificationExecutor(
        ITableNameResolver nameResolver,
        IDataIntegrityQueryBuilder queryBuilder,
        ILogger<TableVerificationExecutor> logger,
        TimeProvider timeProvider)
    {
        _nameResolver = nameResolver ?? throw new ArgumentNullException(nameof(nameResolver));
        _queryBuilder = queryBuilder ?? throw new ArgumentNullException(nameof(queryBuilder));
        _logger = logger ?? throw new ArgumentNullException(nameof(logger));
        _timeProvider = timeProvider ?? throw new ArgumentNullException(nameof(timeProvider));
    }

    public async Task<TableVerificationResult> VerifyTableAsync(
        EntityModel entity,
        string sourceConnectionString,
        string targetConnectionString,
        DataIntegrityVerificationOptions options,
        CancellationToken cancellationToken = default)
    {
        var stopwatch = Stopwatch.StartNew();

        try
        {
            // Step 1: Resolve names
            var targetTableName = _nameResolver.ResolveTargetTableName(entity);
            var columnMappings = _nameResolver.ResolveColumnMappings(entity);
            var (sourcePk, targetPk) = _nameResolver.ResolvePrimaryKeyColumn(entity);

            _logger.LogInformation(
                "Verifying table {LogicalName} (source: {PhysicalName}, target: {TargetName})",
                entity.LogicalName.Value,
                entity.PhysicalName.Value,
                targetTableName);

            // Step 2: Build queries
            var sourceQuery = _queryBuilder.BuildSourceVerificationQuery(
                entity, columnMappings, sourcePk, options.HashAlgorithm);
            var targetQuery = _queryBuilder.BuildTargetVerificationQuery(
                entity, targetTableName, columnMappings, targetPk, options.HashAlgorithm);

            // Step 3: Execute queries in parallel
            var sourceTask = ExecuteVerificationQueryAsync(
                sourceConnectionString, sourceQuery, options.CommandTimeoutSeconds, cancellationToken);
            var targetTask = ExecuteVerificationQueryAsync(
                targetConnectionString, targetQuery, options.CommandTimeoutSeconds, cancellationToken);

            await Task.WhenAll(sourceTask, targetTask).ConfigureAwait(false);

            var sourceResult = await sourceTask;
            var targetResult = await targetTask;

            // Step 4: Compare results
            var status = DetermineStatus(sourceResult, targetResult, columnMappings.Length);
            var nullComparisons = BuildNullCountComparisons(
                sourceResult, targetResult, columnMappings);

            // Step 5: Detect type conversions (if enabled)
            var typeWarnings = options.IncludeDataTypeWarnings
                ? DetectDataTypeConversions(entity)
                : ImmutableArray<DataTypeConversionWarning>.Empty;

            stopwatch.Stop();

            return new TableVerificationResult(
                entity.Module.Value,
                entity.LogicalName.Value,
                entity.PhysicalName.Value,
                targetTableName,
                status,
                sourceResult.RowCount,
                targetResult.RowCount,
                sourceResult.TableHash,
                targetResult.TableHash,
                nullComparisons,
                typeWarnings,
                stopwatch.Elapsed,
                ErrorMessage: null
            );
        }
        catch (SqlException ex)
        {
            _logger.LogError(ex, "SQL error verifying table {LogicalName}", entity.LogicalName.Value);
            stopwatch.Stop();

            return new TableVerificationResult(
                entity.Module.Value,
                entity.LogicalName.Value,
                entity.PhysicalName.Value,
                targetTableName: "N/A",
                TableVerificationStatus.QueryError,
                SourceRowCount: 0,
                TargetRowCount: 0,
                SourceHash: null,
                TargetHash: null,
                ImmutableArray<ColumnNullCountComparison>.Empty,
                ImmutableArray<DataTypeConversionWarning>.Empty,
                stopwatch.Elapsed,
                ErrorMessage: ex.Message
            );
        }
    }

    private async Task<VerificationQueryResult> ExecuteVerificationQueryAsync(
        string connectionString,
        string query,
        int commandTimeoutSeconds,
        CancellationToken cancellationToken)
    {
        await using var connection = new SqlConnection(connectionString);
        await connection.OpenAsync(cancellationToken).ConfigureAwait(false);

        await using var command = connection.CreateCommand();
        command.CommandText = query;
        command.CommandTimeout = commandTimeoutSeconds;

        await using var reader = await command.ExecuteReaderAsync(cancellationToken).ConfigureAwait(false);

        if (!await reader.ReadAsync(cancellationToken).ConfigureAwait(false))
        {
            throw new InvalidOperationException("Verification query returned no rows.");
        }

        // First column: RowCount
        var rowCount = reader.GetInt64(0);

        // Middle columns: NULL counts (skip for now, will parse separately)
        var nullCounts = new Dictionary<string, long>(StringComparer.OrdinalIgnoreCase);
        for (int i = 1; i < reader.FieldCount - 1; i++)
        {
            var columnName = reader.GetName(i).Replace("_NotNullCount", "");
            nullCounts[columnName] = reader.GetInt64(i);
        }

        // Last column: TableHash
        var tableHash = reader.IsDBNull(reader.FieldCount - 1)
            ? null
            : (byte[])reader.GetValue(reader.FieldCount - 1);

        return new VerificationQueryResult(rowCount, nullCounts, tableHash);
    }

    private TableVerificationStatus DetermineStatus(
        VerificationQueryResult source,
        VerificationQueryResult target,
        int expectedColumnCount)
    {
        if (source.RowCount != target.RowCount)
            return TableVerificationStatus.RowCountMismatch;

        if (source.TableHash is null || target.TableHash is null)
            return TableVerificationStatus.QueryError;

        if (!source.TableHash.SequenceEqual(target.TableHash))
            return TableVerificationStatus.HashMismatch;

        // Check NULL counts
        foreach (var kvp in source.NullCounts)
        {
            if (!target.NullCounts.TryGetValue(kvp.Key, out var targetCount) || kvp.Value != targetCount)
                return TableVerificationStatus.NullCountMismatch;
        }

        return TableVerificationStatus.Matched;
    }

    private ImmutableArray<ColumnNullCountComparison> BuildNullCountComparisons(
        VerificationQueryResult source,
        VerificationQueryResult target,
        ImmutableArray<(string PhysicalColumnName, string LogicalColumnName)> columnMappings)
    {
        var builder = ImmutableArray.CreateBuilder<ColumnNullCountComparison>(columnMappings.Length);

        foreach (var (physical, logical) in columnMappings)
        {
            var sourceCount = source.NullCounts.GetValueOrDefault(physical, 0);
            var targetCount = target.NullCounts.GetValueOrDefault(logical, 0);
            var matches = sourceCount == targetCount;

            builder.Add(new ColumnNullCountComparison(
                logical, physical, sourceCount, targetCount, matches));
        }

        return builder.ToImmutable();
    }

    private ImmutableArray<DataTypeConversionWarning> DetectDataTypeConversions(EntityModel entity)
    {
        // TODO: Compare entity.Attributes[].OnDisk.SqlType with target schema
        // For M1.3 v1, assume no conversions (or defer to manual inspection)
        return ImmutableArray<DataTypeConversionWarning>.Empty;
    }

    private sealed record VerificationQueryResult(
        long RowCount,
        Dictionary<string, long> NullCounts,
        byte[]? TableHash);
}
```

---

### 4.4 DataIntegrityVerificationOrchestrator

**Purpose**: Coordinate verification across all tables, produce final report.

**Interface**:
```csharp
public interface IDataIntegrityVerificationOrchestrator
{
    Task<DataIntegrityVerificationReport> VerifyAsync(
        DataIntegrityVerificationContext context,
        CancellationToken cancellationToken = default);
}
```

**Implementation**:
```csharp
public sealed class DataIntegrityVerificationOrchestrator : IDataIntegrityVerificationOrchestrator
{
    private readonly ITableVerificationExecutor _executor;
    private readonly ILogger<DataIntegrityVerificationOrchestrator> _logger;
    private readonly TimeProvider _timeProvider;

    public DataIntegrityVerificationOrchestrator(
        ITableVerificationExecutor executor,
        ILogger<DataIntegrityVerificationOrchestrator> logger,
        TimeProvider timeProvider)
    {
        _executor = executor ?? throw new ArgumentNullException(nameof(executor));
        _logger = logger ?? throw new ArgumentNullException(nameof(logger));
        _timeProvider = timeProvider ?? throw new ArgumentNullException(nameof(timeProvider));
    }

    public async Task<DataIntegrityVerificationReport> VerifyAsync(
        DataIntegrityVerificationContext context,
        CancellationToken cancellationToken = default)
    {
        var startTime = _timeProvider.GetUtcNow();
        var results = ImmutableArray.CreateBuilder<TableVerificationResult>();
        var warnings = ImmutableArray.CreateBuilder<string>();

        _logger.LogInformation(
            "Starting data integrity verification for {Count} entities",
            context.EntitiesToVerify.Length);

        foreach (var entityKey in context.EntitiesToVerify)
        {
            var parts = entityKey.Split("::");
            if (parts.Length != 2)
            {
                warnings.Add($"Invalid entity key format: {entityKey}");
                continue;
            }

            var moduleName = parts[0];
            var logicalName = parts[1];

            var entity = context.Model.Modules
                .FirstOrDefault(m => m.Name.Value.Equals(moduleName, StringComparison.OrdinalIgnoreCase))
                ?.Entities
                .FirstOrDefault(e => e.LogicalName.Value.Equals(logicalName, StringComparison.OrdinalIgnoreCase));

            if (entity is null)
            {
                warnings.Add($"Entity not found in model: {entityKey}");
                continue;
            }

            try
            {
                var result = await _executor.VerifyTableAsync(
                    entity,
                    context.SourceConnectionString,
                    context.TargetConnectionString,
                    context.Options,
                    cancellationToken).ConfigureAwait(false);

                results.Add(result);

                // Fail-fast if enabled and mismatch detected
                if (context.Options.FailFastOnMismatch &&
                    result.Status != TableVerificationStatus.Matched)
                {
                    _logger.LogWarning(
                        "Fail-fast triggered: {Table} verification failed with status {Status}",
                        result.LogicalEntityName,
                        result.Status);
                    break;
                }
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Unexpected error verifying entity {EntityKey}", entityKey);
                warnings.Add($"Failed to verify {entityKey}: {ex.Message}");
            }
        }

        var endTime = _timeProvider.GetUtcNow();
        var totalDuration = endTime - startTime;

        var tableResults = results.ToImmutable();
        var tablesMatched = tableResults.Count(r => r.Status == TableVerificationStatus.Matched);
        var tablesWithMismatches = tableResults.Count(r =>
            r.Status is TableVerificationStatus.RowCountMismatch
                or TableVerificationStatus.HashMismatch
                or TableVerificationStatus.NullCountMismatch);
        var tablesWithErrors = tableResults.Count(r =>
            r.Status is TableVerificationStatus.QueryError
                or TableVerificationStatus.SourceTableMissing
                or TableVerificationStatus.TargetTableMissing);

        var overallStatus = DetermineOverallStatus(tablesMatched, tablesWithMismatches, tablesWithErrors);

        return new DataIntegrityVerificationReport(
            startTime,
            endTime,
            totalDuration,
            tableResults.Length,
            tablesMatched,
            tablesWithMismatches,
            tablesWithErrors,
            tableResults,
            warnings.ToImmutable(),
            overallStatus
        );
    }

    private DataIntegrityVerificationStatus DetermineOverallStatus(
        int matched,
        int mismatches,
        int errors)
    {
        if (errors > 0)
            return DataIntegrityVerificationStatus.Failure;

        if (mismatches > 0)
            return DataIntegrityVerificationStatus.PartialSuccess;

        return matched > 0
            ? DataIntegrityVerificationStatus.Success
            : DataIntegrityVerificationStatus.NotRun;
    }
}
```

---

## 5. Integration Points

### 5.1 Integration with LoadHarness

**Scenario**: Verification runs AFTER LoadHarness completes.

**Code Location**: `src/Osm.LoadHarness/LoadHarnessRunner.cs` (or new `LoadHarnessWithVerification` wrapper)

**Approach 1: Wrapper Service (Recommended)**

```csharp
// New service in Osm.LoadHarness
public sealed class LoadHarnessWithVerificationRunner
{
    private readonly ILoadHarnessRunner _loadHarness;
    private readonly IDataIntegrityVerificationOrchestrator _verificationOrchestrator;

    public async Task<LoadHarnessWithVerificationReport> RunAsync(
        LoadHarnessOptions loadHarnessOptions,
        DataIntegrityVerificationContext verificationContext,
        CancellationToken cancellationToken = default)
    {
        // Step 1: Execute LoadHarness (script execution)
        var loadReport = await _loadHarness.RunAsync(loadHarnessOptions, cancellationToken);

        // Step 2: Verify data integrity (post-load)
        var verificationReport = await _verificationOrchestrator.VerifyAsync(
            verificationContext, cancellationToken);

        return new LoadHarnessWithVerificationReport(loadReport, verificationReport);
    }
}

public sealed record LoadHarnessWithVerificationReport(
    LoadHarnessReport LoadHarnessReport,
    DataIntegrityVerificationReport VerificationReport
);
```

**Approach 2: CLI Command Integration**

```csharp
// In CLI verb handler (src/Osm.Cli/Verbs/FullExportVerb.cs or similar)
public async Task<int> ExecuteAsync(FullExportOptions options, CancellationToken cancellationToken)
{
    // ... existing full-export pipeline ...

    // After LoadHarness completes:
    if (options.VerifyDataIntegrity)
    {
        var verificationContext = await DataIntegrityVerificationContext.CreateAsync(
            modelJsonPath: Path.Combine(outputRoot, "model.json"),
            manifestPath: manifestPath,
            namingOverrides: options.NamingOverrides,
            sourceConnectionString: options.SourceConnectionString,
            targetConnectionString: options.TargetConnectionString,
            cancellationToken: cancellationToken
        );

        var verificationReport = await verificationOrchestrator.VerifyAsync(
            verificationContext, cancellationToken);

        // Log results
        LogVerificationReport(verificationReport);

        // Exit with error if verification failed
        if (!verificationReport.IsSuccess)
        {
            return ExitCodes.DataVerificationFailed;
        }
    }

    return ExitCodes.Success;
}
```

---

### 5.2 Report Serialization

**Format**: JSON (similar to `FullExportRunManifest`)

**Output Location**: `<outputRoot>/verification-report.json`

**Schema**:
```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "type": "object",
  "properties": {
    "startedAtUtc": { "type": "string", "format": "date-time" },
    "completedAtUtc": { "type": "string", "format": "date-time" },
    "totalDurationMs": { "type": "number" },
    "totalTablesVerified": { "type": "integer" },
    "tablesMatched": { "type": "integer" },
    "tablesWithMismatches": { "type": "integer" },
    "tablesWithErrors": { "type": "integer" },
    "overallStatus": { "enum": ["Success", "PartialSuccess", "Failure", "NotRun"] },
    "tableResults": {
      "type": "array",
      "items": {
        "type": "object",
        "properties": {
          "logicalEntityName": { "type": "string" },
          "targetTable": { "type": "string" },
          "status": { "enum": ["Matched", "RowCountMismatch", "HashMismatch", "NullCountMismatch", "QueryError"] },
          "sourceRowCount": { "type": "integer" },
          "targetRowCount": { "type": "integer" },
          "nullCountComparisons": { "type": "array" },
          "typeWarnings": { "type": "array" },
          "durationMs": { "type": "number" }
        }
      }
    },
    "globalWarnings": { "type": "array", "items": { "type": "string" } }
  },
  "required": ["startedAtUtc", "completedAtUtc", "overallStatus"]
}
```

**Serializer**:
```csharp
public sealed class DataIntegrityVerificationReportSerializer
{
    private readonly IFileSystem _fileSystem;

    public async Task SerializeAsync(
        DataIntegrityVerificationReport report,
        string filePath,
        CancellationToken cancellationToken = default)
    {
        var json = JsonSerializer.Serialize(report, new JsonSerializerOptions
        {
            WriteIndented = true,
            PropertyNamingPolicy = JsonNamingPolicy.CamelCase,
            Converters = { new JsonStringEnumConverter() }
        });

        await _fileSystem.File.WriteAllTextAsync(filePath, json, cancellationToken);
    }
}
```

---

## 6. Dependency Injection Setup

**Registration** (in `src/Osm.Pipeline/ServiceCollectionExtensions.cs` or new assembly):

```csharp
public static IServiceCollection AddDataIntegrityVerification(this IServiceCollection services)
{
    // Core components (scoped to allow per-verification state)
    services.AddScoped<ITableNameResolver, TableNameResolver>();
    services.AddScoped<IDataIntegrityQueryBuilder, DataIntegrityQueryBuilder>();
    services.AddScoped<ITableVerificationExecutor, TableVerificationExecutor>();
    services.AddScoped<IDataIntegrityVerificationOrchestrator, DataIntegrityVerificationOrchestrator>();

    // Report serialization
    services.AddSingleton<DataIntegrityVerificationReportSerializer>();

    // Wrapper for LoadHarness integration
    services.AddScoped<LoadHarnessWithVerificationRunner>();

    return services;
}
```

**Usage** (in CLI or application startup):
```csharp
var services = new ServiceCollection();
services.AddDataIntegrityVerification();
// ... other registrations ...
var serviceProvider = services.BuildServiceProvider();
```

---

## 7. Test Scenarios

### 7.1 Unit Tests

**Test Suite**: `Osm.DataIntegrity.Tests`

**Key Test Cases**:

1. **TableNameResolver Tests**
   - Resolves logical name when no override exists
   - Applies table-level override (dbo.OSUSR_R2K_Order → Order)
   - Applies entity-level override (Customer → Customers)
   - Preserves column ordering from model.json

2. **DataIntegrityQueryBuilder Tests**
   - Builds source query with physical names
   - Builds target query with logical names
   - Includes all columns in correct order
   - Adds COUNT() per column for NULL counting
   - Uses HASHBYTES with correct algorithm

3. **TableVerificationExecutor Tests**
   - Detects row count mismatch (source 100 rows, target 95 rows)
   - Detects hash mismatch (same row count, different data)
   - Detects NULL count mismatch (same hash, different NULLs)
   - Handles SQL connection errors gracefully
   - Logs verification progress

4. **DataIntegrityVerificationOrchestrator Tests**
   - Verifies all entities in context
   - Aggregates results correctly (matched/mismatches/errors)
   - Respects fail-fast option
   - Produces comprehensive report

### 7.2 Integration Tests

**Test Database Setup**:
- Source DB: OutSystems QA database with physical names
- Target DB: Fresh database with logical names (created via LoadHarness)

**Test Cases**:

1. **E2E Verification Success**
   - Execute full-export pipeline
   - Run LoadHarness to apply scripts
   - Run verification
   - EXPECT: All tables match, OverallStatus = Success

2. **Intentional Data Modification**
   - Run LoadHarness
   - Manually UPDATE one row in target database
   - Run verification
   - EXPECT: HashMismatch for affected table

3. **NULL Preservation**
   - Source has 10 NULLs in Email column
   - Target (after load) has 8 NULLs
   - Run verification
   - EXPECT: NullCountMismatch for Email column

4. **Missing Target Table**
   - LoadHarness skips one table (script missing)
   - Run verification
   - EXPECT: TargetTableMissing status

---

## 8. Implementation Phases

### Phase 1: Core Infrastructure (M1.3.1)
- [ ] Define data models (Context, Result, Report)
- [ ] Implement TableNameResolver
- [ ] Implement DataIntegrityQueryBuilder
- [ ] Unit tests for name resolution and query building

### Phase 2: Verification Execution (M1.3.2)
- [ ] Implement TableVerificationExecutor
- [ ] Add SQL connection handling and error recovery
- [ ] Implement hash comparison logic
- [ ] Implement NULL count comparison logic
- [ ] Unit tests for executor

### Phase 3: Orchestration & Reporting (M1.3.3)
- [ ] Implement DataIntegrityVerificationOrchestrator
- [ ] Implement report serialization (JSON)
- [ ] Add logging and progress tracking
- [ ] Unit tests for orchestrator

### Phase 4: Integration (M1.3.4)
- [ ] Create LoadHarnessWithVerificationRunner wrapper
- [ ] Integrate with CLI verb (full-export --verify-data-integrity)
- [ ] Add configuration options (hash algorithm, fail-fast)
- [ ] Integration tests (E2E with real databases)

### Phase 5: Documentation & Refinement (M1.3.5)
- [ ] User documentation (how to interpret verification reports)
- [ ] Performance tuning (parallel table verification)
- [ ] Error message improvements
- [ ] Edge case handling (empty tables, large BLOBs)

---

## 9. Dependencies

**NuGet Packages** (likely already referenced):
- `Microsoft.Data.SqlClient` (SQL Server connectivity)
- `System.Text.Json` (report serialization)
- `Microsoft.Extensions.Logging` (logging)
- `System.IO.Abstractions` (file system abstraction)

**Project References**:
- `Osm.Domain` (EntityModel, AttributeModel, NamingOverrideOptions)
- `Osm.Pipeline` (FullExportRunManifest, OsmModel)
- `Osm.LoadHarness` (LoadHarnessRunner, LoadHarnessReport)

---

## 10. Open Questions & Future Work

### 10.1 Open Questions

1. **Q: Should verification run in parallel (all tables concurrently)?**
   - **Consideration**: ~100 tables × ~100k rows = potential DB load spike
   - **Recommendation**: Start sequential, add parallel option in Phase 5 with concurrency limit

2. **Q: How to handle target tables with additional data (not from source)?**
   - **Scenario**: Target has manual inserts outside of LoadHarness
   - **Recommendation**: Row count check will detect this; flag as warning not error

3. **Q: What if source database is read-only (no access)?**
   - **Scenario**: Verification against production source might be blocked
   - **Recommendation**: Require source DB access; future work could snapshot source checksums during extraction

### 10.2 Future Enhancements (Post-M1.3)

1. **M2.2: UAT-Users Transformation Verification**
   - Verify user FK remapping followed mapping rules
   - Compare transformed columns separately from non-transformed columns

2. **Performance Optimization**
   - Parallel table verification with configurable concurrency
   - Incremental verification (only verify changed tables since last run)
   - Sampling mode (verify random subset of rows for large tables)

3. **Advanced Reporting**
   - HTML report with drill-down details
   - Diff output showing mismatched rows (requires row-level comparison)
   - Integration with monitoring systems (emit metrics)

4. **Snapshot-Based Verification**
   - Capture source checksums during extraction (no live DB access needed)
   - Store checksums in manifest for later verification

---

*Specification complete: 2025-11-18*
*Ready for implementation in phases M1.3.1 through M1.3.5*
